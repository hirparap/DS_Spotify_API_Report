{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> DS 3000 - Spring 2020</h2> </center>\n",
    "<center> <h3> DS Report</h3> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3> Song Popularity Prediction</h3> </center>\n",
    "<center><h4>Chidubem Anemeje, Pavan Hirpara, Genevieve Jawor, Cameron Scoons</h4></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executive Summary:\n",
    "\n",
    "For our project, we chose to work with the Spotify API which includes audio features of songs and their popularity on the streaming platform in order to predict the popularity of a song based on its audio features using machine learning models. We found this topic to have a practical application in the world of music as this could aid in release strategies and other marketing aspects.\n",
    "\n",
    "**Method**: Our dataset consisted of 10 feature attributes which were the audio features provided by the Spotify API and the target value being the popularity of the track on the streaming platform. Using the dataset, we tested multiple hypotheses relating the effect of specific audio features on a song’s popularity and trained models to predict the popularity of a song based on the audio features.\n",
    "\n",
    "**Results**: During our hypothesis testing, we found that the data was \n",
    "\n",
    "**Discussion**: In the future, we would like to fine tune our existing models to find better parameters for this specific dataset. Furthermore, exploring neural networks may lead to a greater accuracy in our predictions of popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. <a href='#1'>INTRODUCTION</a>\n",
    "2. <a href='#2'>METHOD</a>\n",
    "3. <a href='#3'>RESULTS</a>\n",
    "4. <a href='#4'>DISCUSSION</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, orient your readers to your project. You've already written some of these in previous deliverables. Based on your final analysis, revise your problem statement and write a concise introduction section. This section should touch upon the following points, but should be written in full paragraphs. Your writing should incorporate all of these points (and more if you like) in a coherent way. Remember that you are trying to convince your readers that this is an important problem to tackle. \n",
    "\n",
    "Problem Statement\n",
    "* Describe the problem you would like to tackle. \n",
    "* What is the topic of your project? \n",
    "* What do you want to learn about it?\n",
    "\n",
    "Significance of the Problem\n",
    "* Why is it important to tackle this problem in your project?\n",
    "* In what ways could the insights from this project be useful?\n",
    "* Has there been previous work on your topic? Do some research into your topic. Cite your sources appropriately. You can use the numbered reference format or APA (if you are more comfortable with it).\n",
    "\n",
    "Questions/Hypothesis\n",
    "* End this section with a list of questions and hypotheses\n",
    "* You should tie these questions/hypotheses to the problem statement and its significance\n",
    "    * e.g. Given the aforementioned problem and its importance, we set out to tackle the following questions:\n",
    "    \n",
    "**Requirement:**\n",
    "* You should have at least one question tapping into the comparison of various machine learning algorithms in predicting your target variable from your features variables.\n",
    "* You should have at least one hypothesis regarding the relationship between two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Acquisition\n",
    "\n",
    "* Describe where you obtained your data. Provide a link to the original source. \n",
    "* If you scraped your data, include your code as a separate script file.\n",
    "* Your data should be stored in an online repository (e.g., GitHub) and your code should retrieve your data from that online resource. You can read csv files from the Web in the same way that you read files from local drive.\n",
    "* Describe the dataset and variables. What do variables represent?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained our data through scraping using the Spotify API as well as the Billboard API, by finding high popularity songs through the charts and low popularity songs through the Spotify API The code to gather the data is included in a separate script file/in the GitHub repository. The data was stored in a public repository on GitHub as well.\n",
    "* Github: https://github.com/hirparap/DS_Spotify_API_Report\n",
    "* Spotify API: [Web API](https://developer.spotify.com/documentation/web-api/)\n",
    "* Billboard API: [billboard.py](https://github.com/guoguo12/billboard-charts)\n",
    "\n",
    "Our dataset consists of 11 important attributes describing the audio features of a certain track on Spotify, including a target attribute that is the Spotify popularity of the track on the platform. We choose to use this as a representation of the success of the song because in today’s music world, streaming is the most widely used method for music listening.\n",
    "Some of the feature attributes gathered from the Spotify API were Acousticness, Danceability, Speechiness, Energy, Liveness, Valence, Key, Mode, Tempo, and Duration. The key variables of interest for our hypothesis were danceability, valence, and tempo. We selected these features due to the fact that many songs that make it to the modern Billboard charts are uptempo dance songs made for the radio.\n",
    "Included below is a more in depth breakdown of the variables:\n",
    "* Acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic\n",
    "* Danceability: A value from 0.0 to 1.0 describing how suitable a track is for dancing\n",
    "* Speechiness: A value from 0.0 to 1.0 describing the presence of spoken words in a track\n",
    "* Energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity\n",
    "* Liveness:  A value from 0.0 to 1.0 detecting the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live\n",
    "* Valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track\n",
    "* Key: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation. If no key was detected, the value is -1\n",
    "* Mode: Mode indicates the modality of a track. Major is represented by 1 and minor is 0.\n",
    "* Tempo: The overall estimated tempo of a track in beats per minute (BPM)\n",
    "* Duration: The duration of the track in milliseconds\n",
    "* Popularity: A measure from 0 to 100 describing how popular the track is on Spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Variables\n",
    "* If you are testing hypotheses, what are your IVs and DVs?\n",
    "* For your predictive models, what are your features and target variables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>IVs and DVs for Hypotheses</u></h4>\n",
    "\n",
    "(1) Higher danceability is associated with higher popularity tracks\n",
    "* IVs: Danceability\n",
    "* DVs: Popularity\n",
    "\n",
    "(2) Higher valence is associated with higher popularity tracks\n",
    "* IVs: Valence\n",
    "* DVs: Popularity\n",
    "\n",
    "(3) Higher tempo is associated with higher popularity tracks\n",
    "* IVs: Tempo\n",
    "* DVs: Popularity\n",
    "\n",
    "<h4><u>Features and Target Variables for Predictive Models</u></h4>\n",
    "For our predictive models, our target variable will be the popularity of the song on the Spotify streaming platform, ranging from 0 to 100. All of the other aforementioned attributes will serve as the features for training the models. Specifically, Acousticness, Danceability, Speechiness, Energy, Liveness, Valence, Key, Mode, Tempo, and Duration will all be our feature variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Data Analysis\n",
    "* Specifically describe your predictive model. What outcome variable are you going to predict from what feature variables?\n",
    "* Describe whether this is a supervised or unsupervised learning problem. Also identify the sub-category of the learning task (e.g. classification).\n",
    "* What machine learning algorithms are you going to use? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We intend to create a predictor that can estimate a track's popularity on Spotify based on the feature attributes described above. We will be utilizing all the features in the dataset at first, and will conduct feature selection afterwards to try and improve accuracy of our model.\n",
    "\n",
    "Since we are attempting to output a numerical score from 0 to 100 to indicate popularity, we decided to use supervised regression models. By comparing the performance of a variety of models (Linear Regression, Ridge, Lasso, k-Nearest Neighbor, Decision Tree and Random Forest Tree), we hope to find the best predictor of popularity. Descriptions of each model can be seen below:\n",
    "* Linear Regression: Attempts to learn weights of features to predict a sample’s class\n",
    "* Ridge: Linear Regression with L2 regularization to help simplify coefficients and hopefully improve performance. \n",
    "* Lasso: Linear Regression with L1 regularization to help simplify coefficients and hopefully improve performance.\n",
    "* k-Nearest Neighbor: Predicts a sample’s class by averaging the values of the k-nearest neighbors  \n",
    "* Decision Tree Regression: Learns a series of true/false “decisions” to predict a sample’s class\n",
    "* Random Forest Tree Regression: Fits a number of decision tree regressors on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting\n",
    "\n",
    "We decided to use Linear Regression as this would provide a decent baseline for our testing of other models. We also used Ridge and Lasso regression to observe the effect of regularization on the linear model. K-Nearest Neighbor was chosen as we thought it would be interesting to see how effective similar songs could be at predicting popularity. Decision Tree Regression was tested because it can model non-linear data. Lastly, Random Forest Tree Regression was tested as often outperforms standard decision trees. \n",
    "\n",
    "<h4><u>Feature Selection</u></h4>\n",
    "We had a limited set of variables due to the few ways available to quantify song characteristics. Therefore, we used every feature that was obtainable from Spotify. Later we will do feature selection to find the most important variables in prediction and hopefully use a subset of these to improve our models. This will also help evaluate our hypotheses about danceability, valence, and tempo’s impact on Spotify popularity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Wrangling\n",
    "* Perform simple data cleaning (delete extra columns, deal with NA values, etc.)\n",
    "* Perform data wrangling to extract your features and target values (e.g., grouping your dataframe by columns, applying functions to format dataframes, etc.)\n",
    "* Preprocess your variables (e.g., scaling/transforming feature variables to normalize them)\n",
    "* Feature extraction (dummy variables, new features from existing features, etc.)\n",
    "* Use one feature selection technique to select a subset of your original features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_samples():\n",
    "    samples = pd.read_csv(\"https://raw.githubusercontent.com/hirparap/DS_Spotify_API_Report/master/combined_samples.csv\").drop(\"Unnamed: 0\", axis = 1)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                   Name  \\\n0                       All I Want for Christmas Is You   \n1                                      Jingle Bell Rock   \n2                     Rockin' Around The Christmas Tree   \n3              A Holly Jolly Christmas - Single Version   \n4           The Christmas Song (Merry Christmas To You)   \n...                                                 ...   \n1995  The Spelling Rules / My Favorite Moment of the...   \n1996                                 No Sé Vivir Sin Ti   \n1997  Divertimento No. 11 in D Major, K. 251: III. A...   \n1998                   Etude Op. 25 : No. 12 in C Minor   \n1999                             Dulce Ivonne - En Vivo   \n\n                                                 Artist  Acousticness  \\\n0                                          Mariah Carey        0.1640   \n1                                           Bobby Helms        0.6430   \n2                                            Brenda Lee        0.6140   \n3                                             Burl Ives        0.5790   \n4                                         Nat King Cole        0.9200   \n...                                                 ...           ...   \n1995  25th Annual Putnam County Spelling Bee Origina...        0.8020   \n1996                                 Conjunto Primavera        0.0698   \n1997                            Wolfgang Amadeus Mozart        0.9200   \n1998                                    Frédéric Chopin        0.9860   \n1999                                        Liran' Roll        0.1480   \n\n      Danceability  Speechiness  Energy  Liveness  Valence   Key  Mode  \\\n0            0.335       0.0386  0.6250    0.0708   0.3460   7.0   1.0   \n1            0.754       0.0363  0.4240    0.0652   0.8060   2.0   1.0   \n2            0.589       0.0502  0.4720    0.5050   0.8980   8.0   1.0   \n3            0.683       0.0303  0.3750    0.0760   0.8880   0.0   1.0   \n4            0.319       0.0341  0.2100    0.1380   0.2090   1.0   1.0   \n...            ...          ...     ...       ...      ...   ...   ...   \n1995         0.527       0.1550  0.2890    0.1060   0.4870   2.0   1.0   \n1996         0.467       0.0305  0.5370    0.1450   0.5560  10.0   1.0   \n1997         0.279       0.0421  0.0727    0.1880   0.2030   9.0   1.0   \n1998         0.183       0.0333  0.1730    0.1120   0.0736   5.0   0.0   \n1999         0.398       0.0665  0.9380    0.8800   0.5890   2.0   1.0   \n\n        Tempo  Duration  Popularity  \n0     150.277  241107.0        70.0  \n1     119.705  130973.0        61.0  \n2      67.196  126267.0        62.0  \n3     140.467  135533.0        52.0  \n4      78.696  192160.0        58.0  \n...       ...       ...         ...  \n1995  169.072  101947.0        28.0  \n1996  146.465  213253.0        20.0  \n1997  130.693  224760.0        26.0  \n1998   75.121  166253.0        13.0  \n1999   75.667  278813.0        29.0  \n\n[2000 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Artist</th>\n      <th>Acousticness</th>\n      <th>Danceability</th>\n      <th>Speechiness</th>\n      <th>Energy</th>\n      <th>Liveness</th>\n      <th>Valence</th>\n      <th>Key</th>\n      <th>Mode</th>\n      <th>Tempo</th>\n      <th>Duration</th>\n      <th>Popularity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>All I Want for Christmas Is You</td>\n      <td>Mariah Carey</td>\n      <td>0.1640</td>\n      <td>0.335</td>\n      <td>0.0386</td>\n      <td>0.6250</td>\n      <td>0.0708</td>\n      <td>0.3460</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>150.277</td>\n      <td>241107.0</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Jingle Bell Rock</td>\n      <td>Bobby Helms</td>\n      <td>0.6430</td>\n      <td>0.754</td>\n      <td>0.0363</td>\n      <td>0.4240</td>\n      <td>0.0652</td>\n      <td>0.8060</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>119.705</td>\n      <td>130973.0</td>\n      <td>61.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rockin' Around The Christmas Tree</td>\n      <td>Brenda Lee</td>\n      <td>0.6140</td>\n      <td>0.589</td>\n      <td>0.0502</td>\n      <td>0.4720</td>\n      <td>0.5050</td>\n      <td>0.8980</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>67.196</td>\n      <td>126267.0</td>\n      <td>62.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A Holly Jolly Christmas - Single Version</td>\n      <td>Burl Ives</td>\n      <td>0.5790</td>\n      <td>0.683</td>\n      <td>0.0303</td>\n      <td>0.3750</td>\n      <td>0.0760</td>\n      <td>0.8880</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>140.467</td>\n      <td>135533.0</td>\n      <td>52.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Christmas Song (Merry Christmas To You)</td>\n      <td>Nat King Cole</td>\n      <td>0.9200</td>\n      <td>0.319</td>\n      <td>0.0341</td>\n      <td>0.2100</td>\n      <td>0.1380</td>\n      <td>0.2090</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>78.696</td>\n      <td>192160.0</td>\n      <td>58.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>The Spelling Rules / My Favorite Moment of the...</td>\n      <td>25th Annual Putnam County Spelling Bee Origina...</td>\n      <td>0.8020</td>\n      <td>0.527</td>\n      <td>0.1550</td>\n      <td>0.2890</td>\n      <td>0.1060</td>\n      <td>0.4870</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>169.072</td>\n      <td>101947.0</td>\n      <td>28.0</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>No Sé Vivir Sin Ti</td>\n      <td>Conjunto Primavera</td>\n      <td>0.0698</td>\n      <td>0.467</td>\n      <td>0.0305</td>\n      <td>0.5370</td>\n      <td>0.1450</td>\n      <td>0.5560</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>146.465</td>\n      <td>213253.0</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>Divertimento No. 11 in D Major, K. 251: III. A...</td>\n      <td>Wolfgang Amadeus Mozart</td>\n      <td>0.9200</td>\n      <td>0.279</td>\n      <td>0.0421</td>\n      <td>0.0727</td>\n      <td>0.1880</td>\n      <td>0.2030</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>130.693</td>\n      <td>224760.0</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>Etude Op. 25 : No. 12 in C Minor</td>\n      <td>Frédéric Chopin</td>\n      <td>0.9860</td>\n      <td>0.183</td>\n      <td>0.0333</td>\n      <td>0.1730</td>\n      <td>0.1120</td>\n      <td>0.0736</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>75.121</td>\n      <td>166253.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>Dulce Ivonne - En Vivo</td>\n      <td>Liran' Roll</td>\n      <td>0.1480</td>\n      <td>0.398</td>\n      <td>0.0665</td>\n      <td>0.9380</td>\n      <td>0.8800</td>\n      <td>0.5890</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>75.667</td>\n      <td>278813.0</td>\n      <td>29.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 13 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "samples = import_samples()\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_and_target(df):\n",
    "    return (df.drop(columns = [\"Name\", \"Artist\", \"Popularity\"]), df[\"Popularity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = features_and_target(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Acousticness  Danceability  Speechiness  Energy  Liveness  Valence  \\\n0           0.1640         0.335       0.0386  0.6250    0.0708   0.3460   \n1           0.6430         0.754       0.0363  0.4240    0.0652   0.8060   \n2           0.6140         0.589       0.0502  0.4720    0.5050   0.8980   \n3           0.5790         0.683       0.0303  0.3750    0.0760   0.8880   \n4           0.9200         0.319       0.0341  0.2100    0.1380   0.2090   \n...            ...           ...          ...     ...       ...      ...   \n1995        0.8020         0.527       0.1550  0.2890    0.1060   0.4870   \n1996        0.0698         0.467       0.0305  0.5370    0.1450   0.5560   \n1997        0.9200         0.279       0.0421  0.0727    0.1880   0.2030   \n1998        0.9860         0.183       0.0333  0.1730    0.1120   0.0736   \n1999        0.1480         0.398       0.0665  0.9380    0.8800   0.5890   \n\n       Key  Mode    Tempo  Duration  \n0      7.0   1.0  150.277  241107.0  \n1      2.0   1.0  119.705  130973.0  \n2      8.0   1.0   67.196  126267.0  \n3      0.0   1.0  140.467  135533.0  \n4      1.0   1.0   78.696  192160.0  \n...    ...   ...      ...       ...  \n1995   2.0   1.0  169.072  101947.0  \n1996  10.0   1.0  146.465  213253.0  \n1997   9.0   1.0  130.693  224760.0  \n1998   5.0   0.0   75.121  166253.0  \n1999   2.0   1.0   75.667  278813.0  \n\n[2000 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Acousticness</th>\n      <th>Danceability</th>\n      <th>Speechiness</th>\n      <th>Energy</th>\n      <th>Liveness</th>\n      <th>Valence</th>\n      <th>Key</th>\n      <th>Mode</th>\n      <th>Tempo</th>\n      <th>Duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.1640</td>\n      <td>0.335</td>\n      <td>0.0386</td>\n      <td>0.6250</td>\n      <td>0.0708</td>\n      <td>0.3460</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>150.277</td>\n      <td>241107.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.6430</td>\n      <td>0.754</td>\n      <td>0.0363</td>\n      <td>0.4240</td>\n      <td>0.0652</td>\n      <td>0.8060</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>119.705</td>\n      <td>130973.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.6140</td>\n      <td>0.589</td>\n      <td>0.0502</td>\n      <td>0.4720</td>\n      <td>0.5050</td>\n      <td>0.8980</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>67.196</td>\n      <td>126267.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5790</td>\n      <td>0.683</td>\n      <td>0.0303</td>\n      <td>0.3750</td>\n      <td>0.0760</td>\n      <td>0.8880</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>140.467</td>\n      <td>135533.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.9200</td>\n      <td>0.319</td>\n      <td>0.0341</td>\n      <td>0.2100</td>\n      <td>0.1380</td>\n      <td>0.2090</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>78.696</td>\n      <td>192160.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>0.8020</td>\n      <td>0.527</td>\n      <td>0.1550</td>\n      <td>0.2890</td>\n      <td>0.1060</td>\n      <td>0.4870</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>169.072</td>\n      <td>101947.0</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>0.0698</td>\n      <td>0.467</td>\n      <td>0.0305</td>\n      <td>0.5370</td>\n      <td>0.1450</td>\n      <td>0.5560</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>146.465</td>\n      <td>213253.0</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>0.9200</td>\n      <td>0.279</td>\n      <td>0.0421</td>\n      <td>0.0727</td>\n      <td>0.1880</td>\n      <td>0.2030</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>130.693</td>\n      <td>224760.0</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>0.9860</td>\n      <td>0.183</td>\n      <td>0.0333</td>\n      <td>0.1730</td>\n      <td>0.1120</td>\n      <td>0.0736</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>75.121</td>\n      <td>166253.0</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>0.1480</td>\n      <td>0.398</td>\n      <td>0.0665</td>\n      <td>0.9380</td>\n      <td>0.8800</td>\n      <td>0.5890</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>75.667</td>\n      <td>278813.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       70.0\n1       61.0\n2       62.0\n3       52.0\n4       58.0\n        ... \n1995    28.0\n1996    20.0\n1997    26.0\n1998    13.0\n1999    29.0\nName: Popularity, Length: 2000, dtype: float64"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a one hot representation of a given column\n",
    "def one_hot_representation(df):\n",
    "    encoder = OneHotEncoder(sparse = False)\n",
    "    encoded_df = encoder.fit_transform(df)\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dummy variables to represent one hot encoding of possible keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Acousticness  Danceability  Speechiness  Energy  Liveness  Valence  \\\n0           0.1640         0.335       0.0386  0.6250    0.0708   0.3460   \n1           0.6430         0.754       0.0363  0.4240    0.0652   0.8060   \n2           0.6140         0.589       0.0502  0.4720    0.5050   0.8980   \n3           0.5790         0.683       0.0303  0.3750    0.0760   0.8880   \n4           0.9200         0.319       0.0341  0.2100    0.1380   0.2090   \n...            ...           ...          ...     ...       ...      ...   \n1995        0.8020         0.527       0.1550  0.2890    0.1060   0.4870   \n1996        0.0698         0.467       0.0305  0.5370    0.1450   0.5560   \n1997        0.9200         0.279       0.0421  0.0727    0.1880   0.2030   \n1998        0.9860         0.183       0.0333  0.1730    0.1120   0.0736   \n1999        0.1480         0.398       0.0665  0.9380    0.8800   0.5890   \n\n      Mode    Tempo  Duration  key_0  ...  key_2  key_3  key_4  key_5  key_6  \\\n0      1.0  150.277  241107.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n1      1.0  119.705  130973.0    0.0  ...    1.0    0.0    0.0    0.0    0.0   \n2      1.0   67.196  126267.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n3      1.0  140.467  135533.0    1.0  ...    0.0    0.0    0.0    0.0    0.0   \n4      1.0   78.696  192160.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n...    ...      ...       ...    ...  ...    ...    ...    ...    ...    ...   \n1995   1.0  169.072  101947.0    0.0  ...    1.0    0.0    0.0    0.0    0.0   \n1996   1.0  146.465  213253.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n1997   1.0  130.693  224760.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n1998   0.0   75.121  166253.0    0.0  ...    0.0    0.0    0.0    1.0    0.0   \n1999   1.0   75.667  278813.0    0.0  ...    1.0    0.0    0.0    0.0    0.0   \n\n      key_7  key_8  key_9  key_10  key_11  \n0       1.0    0.0    0.0     0.0     0.0  \n1       0.0    0.0    0.0     0.0     0.0  \n2       0.0    1.0    0.0     0.0     0.0  \n3       0.0    0.0    0.0     0.0     0.0  \n4       0.0    0.0    0.0     0.0     0.0  \n...     ...    ...    ...     ...     ...  \n1995    0.0    0.0    0.0     0.0     0.0  \n1996    0.0    0.0    0.0     1.0     0.0  \n1997    0.0    0.0    1.0     0.0     0.0  \n1998    0.0    0.0    0.0     0.0     0.0  \n1999    0.0    0.0    0.0     0.0     0.0  \n\n[2000 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Acousticness</th>\n      <th>Danceability</th>\n      <th>Speechiness</th>\n      <th>Energy</th>\n      <th>Liveness</th>\n      <th>Valence</th>\n      <th>Mode</th>\n      <th>Tempo</th>\n      <th>Duration</th>\n      <th>key_0</th>\n      <th>...</th>\n      <th>key_2</th>\n      <th>key_3</th>\n      <th>key_4</th>\n      <th>key_5</th>\n      <th>key_6</th>\n      <th>key_7</th>\n      <th>key_8</th>\n      <th>key_9</th>\n      <th>key_10</th>\n      <th>key_11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.1640</td>\n      <td>0.335</td>\n      <td>0.0386</td>\n      <td>0.6250</td>\n      <td>0.0708</td>\n      <td>0.3460</td>\n      <td>1.0</td>\n      <td>150.277</td>\n      <td>241107.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.6430</td>\n      <td>0.754</td>\n      <td>0.0363</td>\n      <td>0.4240</td>\n      <td>0.0652</td>\n      <td>0.8060</td>\n      <td>1.0</td>\n      <td>119.705</td>\n      <td>130973.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.6140</td>\n      <td>0.589</td>\n      <td>0.0502</td>\n      <td>0.4720</td>\n      <td>0.5050</td>\n      <td>0.8980</td>\n      <td>1.0</td>\n      <td>67.196</td>\n      <td>126267.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5790</td>\n      <td>0.683</td>\n      <td>0.0303</td>\n      <td>0.3750</td>\n      <td>0.0760</td>\n      <td>0.8880</td>\n      <td>1.0</td>\n      <td>140.467</td>\n      <td>135533.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.9200</td>\n      <td>0.319</td>\n      <td>0.0341</td>\n      <td>0.2100</td>\n      <td>0.1380</td>\n      <td>0.2090</td>\n      <td>1.0</td>\n      <td>78.696</td>\n      <td>192160.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>0.8020</td>\n      <td>0.527</td>\n      <td>0.1550</td>\n      <td>0.2890</td>\n      <td>0.1060</td>\n      <td>0.4870</td>\n      <td>1.0</td>\n      <td>169.072</td>\n      <td>101947.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>0.0698</td>\n      <td>0.467</td>\n      <td>0.0305</td>\n      <td>0.5370</td>\n      <td>0.1450</td>\n      <td>0.5560</td>\n      <td>1.0</td>\n      <td>146.465</td>\n      <td>213253.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>0.9200</td>\n      <td>0.279</td>\n      <td>0.0421</td>\n      <td>0.0727</td>\n      <td>0.1880</td>\n      <td>0.2030</td>\n      <td>1.0</td>\n      <td>130.693</td>\n      <td>224760.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>0.9860</td>\n      <td>0.183</td>\n      <td>0.0333</td>\n      <td>0.1730</td>\n      <td>0.1120</td>\n      <td>0.0736</td>\n      <td>0.0</td>\n      <td>75.121</td>\n      <td>166253.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>0.1480</td>\n      <td>0.398</td>\n      <td>0.0665</td>\n      <td>0.9380</td>\n      <td>0.8800</td>\n      <td>0.5890</td>\n      <td>1.0</td>\n      <td>75.667</td>\n      <td>278813.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "keys = features[\"Key\"].values.reshape(-1,1)\n",
    "encoded_df = one_hot_representation(keys)\n",
    "#create better columns names\n",
    "col = ['key_' + str(i) for i in range(12)]\n",
    "key_df = pd.DataFrame(encoded_df, columns = col)\n",
    "features = features.drop(columns=['Key'])\n",
    "features = features.join(key_df)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling of necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Acousticness  Danceability  Speechiness  Energy  Liveness  Valence  \\\n0           0.1640         0.335       0.0386  0.6250    0.0708   0.3460   \n1           0.6430         0.754       0.0363  0.4240    0.0652   0.8060   \n2           0.6140         0.589       0.0502  0.4720    0.5050   0.8980   \n3           0.5790         0.683       0.0303  0.3750    0.0760   0.8880   \n4           0.9200         0.319       0.0341  0.2100    0.1380   0.2090   \n...            ...           ...          ...     ...       ...      ...   \n1995        0.8020         0.527       0.1550  0.2890    0.1060   0.4870   \n1996        0.0698         0.467       0.0305  0.5370    0.1450   0.5560   \n1997        0.9200         0.279       0.0421  0.0727    0.1880   0.2030   \n1998        0.9860         0.183       0.0333  0.1730    0.1120   0.0736   \n1999        0.1480         0.398       0.0665  0.9380    0.8800   0.5890   \n\n      Mode  key_0  key_1  key_2  ...  key_4  key_5  key_6  key_7  key_8  \\\n0      1.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    1.0    0.0   \n1      1.0    0.0    0.0    1.0  ...    0.0    0.0    0.0    0.0    0.0   \n2      1.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    1.0   \n3      1.0    1.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n4      1.0    0.0    1.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...   \n1995   1.0    0.0    0.0    1.0  ...    0.0    0.0    0.0    0.0    0.0   \n1996   1.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n1997   1.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n1998   0.0    0.0    0.0    0.0  ...    0.0    1.0    0.0    0.0    0.0   \n1999   1.0    0.0    0.0    1.0  ...    0.0    0.0    0.0    0.0    0.0   \n\n      key_9  key_10  key_11     Tempo  Duration  \n0       0.0     0.0     0.0  0.634350  0.140707  \n1       0.0     0.0     0.0  0.442369  0.065751  \n2       0.0     0.0     0.0  0.112631  0.062548  \n3       0.0     0.0     0.0  0.572746  0.068854  \n4       0.0     0.0     0.0  0.184847  0.107394  \n...     ...     ...     ...       ...       ...  \n1995    0.0     0.0     0.0  0.752375  0.045996  \n1996    0.0     1.0     0.0  0.610412  0.121750  \n1997    1.0     0.0     0.0  0.511369  0.129581  \n1998    0.0     0.0     0.0  0.162398  0.089762  \n1999    0.0     0.0     0.0  0.165826  0.166369  \n\n[2000 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Acousticness</th>\n      <th>Danceability</th>\n      <th>Speechiness</th>\n      <th>Energy</th>\n      <th>Liveness</th>\n      <th>Valence</th>\n      <th>Mode</th>\n      <th>key_0</th>\n      <th>key_1</th>\n      <th>key_2</th>\n      <th>...</th>\n      <th>key_4</th>\n      <th>key_5</th>\n      <th>key_6</th>\n      <th>key_7</th>\n      <th>key_8</th>\n      <th>key_9</th>\n      <th>key_10</th>\n      <th>key_11</th>\n      <th>Tempo</th>\n      <th>Duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.1640</td>\n      <td>0.335</td>\n      <td>0.0386</td>\n      <td>0.6250</td>\n      <td>0.0708</td>\n      <td>0.3460</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.634350</td>\n      <td>0.140707</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.6430</td>\n      <td>0.754</td>\n      <td>0.0363</td>\n      <td>0.4240</td>\n      <td>0.0652</td>\n      <td>0.8060</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.442369</td>\n      <td>0.065751</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.6140</td>\n      <td>0.589</td>\n      <td>0.0502</td>\n      <td>0.4720</td>\n      <td>0.5050</td>\n      <td>0.8980</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.112631</td>\n      <td>0.062548</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5790</td>\n      <td>0.683</td>\n      <td>0.0303</td>\n      <td>0.3750</td>\n      <td>0.0760</td>\n      <td>0.8880</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.572746</td>\n      <td>0.068854</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.9200</td>\n      <td>0.319</td>\n      <td>0.0341</td>\n      <td>0.2100</td>\n      <td>0.1380</td>\n      <td>0.2090</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.184847</td>\n      <td>0.107394</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>0.8020</td>\n      <td>0.527</td>\n      <td>0.1550</td>\n      <td>0.2890</td>\n      <td>0.1060</td>\n      <td>0.4870</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.752375</td>\n      <td>0.045996</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>0.0698</td>\n      <td>0.467</td>\n      <td>0.0305</td>\n      <td>0.5370</td>\n      <td>0.1450</td>\n      <td>0.5560</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.610412</td>\n      <td>0.121750</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>0.9200</td>\n      <td>0.279</td>\n      <td>0.0421</td>\n      <td>0.0727</td>\n      <td>0.1880</td>\n      <td>0.2030</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.511369</td>\n      <td>0.129581</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>0.9860</td>\n      <td>0.183</td>\n      <td>0.0333</td>\n      <td>0.1730</td>\n      <td>0.1120</td>\n      <td>0.0736</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.162398</td>\n      <td>0.089762</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>0.1480</td>\n      <td>0.398</td>\n      <td>0.0665</td>\n      <td>0.9380</td>\n      <td>0.8800</td>\n      <td>0.5890</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.165826</td>\n      <td>0.166369</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "#scale Tempo and Duration, features not in range 0-1\n",
    "unscaled_features_df = pd.DataFrame(features[[\"Tempo\",\"Duration\"]])\n",
    "scaled_col = scaler.fit_transform(unscaled_features_df)\n",
    "scaled_features_df = pd.DataFrame(scaled_col, columns=[\"Tempo\",\"Duration\"])\n",
    "features = features.drop(columns=[\"Tempo\",\"Duration\"])\n",
    "features[\"Tempo\"] = scaled_features_df[\"Tempo\"]\n",
    "features[\"Duration\"] = scaled_features_df[\"Duration\"]\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFE_feature_selection(num_feat):\n",
    "    select = RFE(DecisionTreeRegressor(), n_features_to_select = num_feat)\n",
    "    select.fit(features, target)\n",
    "    features_selected = select.transform(features)\n",
    "    features_mask = select.get_support()\n",
    "    count = 0\n",
    "    print(\"Selected features after RFE:\")\n",
    "    for feature_index in features_mask:\n",
    "        if (feature_index):\n",
    "            print(\"\\t\" + features.columns[count])\n",
    "        count += 1\n",
    "    print(select.estimator_.feature_importances_)\n",
    "    return features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Selected features after RFE:\n\tAcousticness\n\tDanceability\n\tSpeechiness\n\tEnergy\n\tLiveness\n\tValence\n\tDuration\n[0.12908536 0.31255461 0.10267163 0.09923109 0.0601195  0.16345566\n 0.13288215]\n"
    }
   ],
   "source": [
    "features_selected = RFE_feature_selection(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Data Exploration\n",
    "* Generate appropriate data visualizations for your key variables identified in the previous section\n",
    "* You should have at least three visualizations (and at least two different visualization types)\n",
    "* For each visualization provide an explanation regarding the variables involved and an interpretation of the graph.\n",
    "* If you are using Plotly, insert your visualizations as images as well (upload the graph images to an online source, e.g. github, and link those in Jupyter Notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model Construction\n",
    "* If you proposed hypotheses, conduct your hypothesis tests\n",
    "* For your machine learning question(s), split data into training, validation, and testing sets (or use cross-validation)\n",
    "* Apply machine learning algorithms (apply at least three algorithms)\n",
    "* Train your algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and test set splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(feature_set):\n",
    "    return train_test_split(feature_set, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Acousticness  Danceability  Speechiness   Energy  Liveness  Valence  \\\n1507        0.9960         0.388       0.0500  0.01800    0.1890   0.1800   \n1544        0.8910         0.284       0.0406  0.12000    0.0743   0.2290   \n979         0.1630         0.599       0.0232  0.44800    0.1060   0.1680   \n103         0.5560         0.760       0.0466  0.47900    0.0703   0.9130   \n1316        0.0943         0.150       0.0337  0.54000    0.1060   0.1050   \n...            ...           ...          ...      ...       ...      ...   \n478         0.1050         0.928       0.2870  0.48100    0.1760   0.6130   \n1152        0.0716         0.248       0.0976  0.98800    0.8810   0.1770   \n87          0.4680         0.764       0.0588  0.52800    0.0811   0.4220   \n1777        0.9610         0.219       0.0586  0.00101    0.0949   0.0328   \n308         0.0891         0.586       0.0705  0.90900    0.1190   0.7570   \n\n      Mode  key_0  key_1  key_2  ...  key_4  key_5  key_6  key_7  key_8  \\\n1507   0.0    1.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n1544   0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    1.0   \n979    1.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    1.0   \n103    1.0    0.0    0.0    1.0  ...    0.0    0.0    0.0    0.0    0.0   \n1316   1.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    1.0    0.0   \n...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...   \n478    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0   \n1152   0.0    0.0    0.0    0.0  ...    1.0    0.0    0.0    0.0    0.0   \n87     0.0    0.0    0.0    0.0  ...    0.0    1.0    0.0    0.0    0.0   \n1777   1.0    0.0    0.0    0.0  ...    1.0    0.0    0.0    0.0    0.0   \n308    1.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    1.0   \n\n      key_9  key_10  key_11     Tempo  Duration  \n1507    0.0     0.0     0.0  0.159365  0.132353  \n1544    0.0     0.0     0.0  0.384615  0.202931  \n979     0.0     0.0     0.0  0.287544  0.155879  \n103     0.0     0.0     0.0  0.255273  0.084172  \n1316    0.0     0.0     0.0  0.821740  0.177204  \n...     ...     ...     ...       ...       ...  \n478     1.0     0.0     0.0  0.532180  0.120173  \n1152    0.0     0.0     0.0  0.304493  0.157151  \n87      0.0     0.0     0.0  0.468938  0.105415  \n1777    0.0     0.0     0.0  0.174982  0.018130  \n308     0.0     0.0     0.0  0.277145  0.120044  \n\n[1500 rows x 21 columns]\n"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_dataset(features)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.988      0.265      0.0348     ... 0.1        0.128      0.05937141]\n [0.986      0.435      0.0431     ... 0.142      0.516      0.21945539]\n [0.109      0.592      0.0361     ... 0.167      0.677      0.11583328]\n ...\n [0.0841     0.732      0.0286     ... 0.105      0.548      0.10995297]\n [0.766      0.24       0.037      ... 0.117      0.776      0.08001579]\n [0.474      0.781      0.0295     ... 0.184      0.591      0.16823883]]\n"
    }
   ],
   "source": [
    "X_train_selected, X_test_selected, y_train_selected, y_test_selected = split_dataset(features_selected)\n",
    "print(X_train_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\"Linear Regression\" : LinearRegression(),\n",
    "              \"Ridge\" : Ridge(alpha = 1.0),\n",
    "              \"Lasso\" : Lasso(alpha = 1.0),\n",
    "              \"k-Nearest Neighbor\" : KNeighborsRegressor(n_neighbors = 5),\n",
    "              \"Decision Tree\" : DecisionTreeRegressor(),\n",
    "              \"Random Forest Tree\" :  RandomForestRegressor()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline performance on all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressors_percentage_split(X_train, X_test, y_train, y_test):\n",
    "    for estimator_name, model in estimators.items():\n",
    "        model.fit(X=X_train, y=y_train)\n",
    "        print(estimator_name + \":\")\n",
    "        print(\"\\tR-squared value for training set: \", r2_score(y_train, model.predict(X_train)))\n",
    "        print(\"\\tR-squared value for testing set: \", r2_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Linear Regression:\n\tR-squared value for training set:  0.4360280379119875\n\tR-squared value for testing set:  0.39018333081240264\nRidge:\n\tR-squared value for training set:  0.4358960232002115\n\tR-squared value for testing set:  0.3909831828425756\nLasso:\n\tR-squared value for training set:  0.31520634740705145\n\tR-squared value for testing set:  0.3049784246874614\nk-Nearest Neighbor:\n\tR-squared value for training set:  0.6485902093259184\n\tR-squared value for testing set:  0.5002364553363118\nDecision Tree:\n\tR-squared value for training set:  0.9995050374660375\n\tR-squared value for testing set:  0.48845821871588413\nRandom Forest Tree:\n\tR-squared value for training set:  0.961462061464433\n\tR-squared value for testing set:  0.69338179745424\n"
    }
   ],
   "source": [
    "regressors_percentage_split(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selected performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Linear Regression:\n\tR-squared value for training set:  0.4239118343263528\n\tR-squared value for testing set:  0.37552231712279416\nRidge:\n\tR-squared value for training set:  0.42376409254957204\n\tR-squared value for testing set:  0.37589118047224057\nLasso:\n\tR-squared value for training set:  0.327227212954747\n\tR-squared value for testing set:  0.2952988632413043\nk-Nearest Neighbor:\n\tR-squared value for training set:  0.7077481882830494\n\tR-squared value for testing set:  0.5225286407951597\nDecision Tree:\n\tR-squared value for training set:  0.9994038524807572\n\tR-squared value for testing set:  0.5171606221352318\nRandom Forest Tree:\n\tR-squared value for training set:  0.9589745686502824\n\tR-squared value for testing set:  0.7366913444162253\n"
    }
   ],
   "source": [
    "regressors_percentage_split(X_train_selected, X_test_selected, y_train_selected, y_test_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Model Evaluation\n",
    "* Evaluate the performance of your algorithms on appropriate evaluation metrics, using your validation set\n",
    "* Interpret your results from multiple models (and hypothesis tests, if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Model Optimization\n",
    "* Tune your models using appropriate hyperparameters\n",
    "* Explain why you are doing this (e.g., to avoid overfitting, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN parameters\n",
    "knn_param_grid = {\"n_neighbors\":[1, 5, 10], \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"]}\n",
    "#decision tree parameters\n",
    "dt_param_grid = {\"max_depth\":[10, 100, 200], \"min_samples_split\": [2, 10, 100]}\n",
    "#random forest tree parameters\n",
    "rf_param_grid = {\"n_estimators\":[100, 250, 500], \"max_features\": [\"auto\", \"sqrt\"], \"min_samples_split\": [2, 5, 10],\"min_samples_leaf\": [1, 2, 4], \"bootstrap\": [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, parameters):\n",
    "    grid_search = GridSearchCV(model, parameters, cv = 10)\n",
    "    grid_search.fit(X = X_train_selected, y = y_train_selected)\n",
    "    \n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Training set score with best parameters: \", grid_search.score(X_train_selected, y_train_selected))\n",
    "    print(\"Test set score with best parameters: \", grid_search.score(X_test_selected, y_test_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best parameters:  {'metric': 'manhattan', 'n_neighbors': 5}\nTraining set score with best parameters:  0.714498783786873\nTest set score with best parameters:  0.5328051973433704\n"
    }
   ],
   "source": [
    "grid_search(KNeighborsRegressor(), knn_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best parameters:  {'max_depth': 10, 'min_samples_split': 10}\nTraining set score with best parameters:  0.8111254072855809\nTest set score with best parameters:  0.5149847808200103\n"
    }
   ],
   "source": [
    "grid_search(DecisionTreeRegressor(), dt_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best parameters:  {'bootstrap': False, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\nTraining set score with best parameters:  0.9994038524807572\nTest set score with best parameters:  0.770646616335909\n"
    }
   ],
   "source": [
    "grid_search(RandomForestRegressor(), rf_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Model Testing\n",
    "* Test your tuned algorithms using your testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DISCUSSION\n",
    "* Provide a summary of the steps you took to analyze your data and test your predictive model\n",
    "* Intepret your findings from 3.4., 3.5, and 3.6\n",
    "    * Which algorithms did you compare?\n",
    "    * Which algorithm(s) revealed best performance?\n",
    "    * Which algorithm(s) should be used for your predictive model?\n",
    "* If you tested hypotheses, interpret the results. What does it mean to have significant/non-significant differences with regards to your data?\n",
    "\n",
    "\n",
    "* End this section with a conclusion paragraph containing some pointers for future work \n",
    "    *(e.g., get more data, perform another analysis, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRIBUTIONS\n",
    "* Describe each team member's contributions to the report (who did what in each section)\n",
    "* Remember this is a team effort!\n",
    "* Each member of your team will provide peer evaluation of other team members. Your final grade on the project will be based on those peer evaluations. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}